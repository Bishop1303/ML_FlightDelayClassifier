{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Regularization_flightmodel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPX/JmC0HmO+DNolsFIFldt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bishop1303/ML_PySpark/blob/dev/ML_Regularization_flightmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esc7TpsrUcQp",
        "outputId": "b5dd876a-1698-486d-e573-398b19f1cdb3"
      },
      "source": [
        "#Carica il drive con i dati:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNLVZmpiUOF3"
      },
      "source": [
        "# Getting the softwares:\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.1.1/spark-3.1.1-bin-hadoop2.7.tgz\n",
        "!tar -xvf spark-3.1.1-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "\n",
        "\n",
        "# To use spark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop2.7\"\n",
        "\n",
        "# SparkSession\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihVlhgH-Uddp"
      },
      "source": [
        "# Flight duration model: More features!\n",
        "\n",
        "Add more features to model will not necessarily result in a better model. Adding some features might improve the model. Adding other features might make it worse.\n",
        "\n",
        "More features will always make the model more complicated and difficult to interpret.\n",
        "\n",
        "These are the features include in the model:\n",
        "\n",
        "* **km**\n",
        "* **org** (origin airport, one-hot encoded, 8 levels)\n",
        "* **depart** (departure time, binned in 3 hour intervals, one-hot encoded, 8 levels)\n",
        "* **dow** (departure day of week, one-hot encoded, 7 levels) and\n",
        "* **mon** (departure month, one-hot encoded, 12 levels).  \n",
        "\n",
        "These have to been assembled into the features column, which is a *sparse representation* of 32 columns (*one-hot encoding* produces a number of columns which is one fewer than the number of levels)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xvr85qtiVKyY"
      },
      "source": [
        "from pyspark.ml.feature import Bucketizer, OneHotEncoder\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.sql.functions import round\n",
        "\n",
        "\n",
        "### DATA PREPARATION ###\n",
        "\n",
        "# Read raw data to pyspark\n",
        "flights = spark.read.csv(\"/content/drive/My Drive/flights.csv\", inferSchema=True, header=True, mode='FAILFAST')\n",
        "#flights.show()\n",
        "#flights.printSchema()\n",
        "\n",
        "### DATA PREPARATION ###\n",
        "\n",
        "# Remove the 'flight' column\n",
        "flights_drop_column = flights.drop('flight')\n",
        "\n",
        "# Remove records with missing 'delay' values or NA values\n",
        "flights_none_missing = flights_drop_column.filter((flights_drop_column.delay.isNotNull()) & \\\n",
        "                                                  (flights_drop_column.delay != 'NA'))\n",
        "\n",
        "# Test delay\n",
        "flights_none_missing = flights_none_missing.withColumn('delay', flights_none_missing['delay'].cast('int'))\n",
        "\n",
        "# Check on dataframe\n",
        "#print('The Schema is: ')\n",
        "#flights_none_missing.printSchema()\n",
        "#print('=====================================================')\n",
        "#print('Informative rows after dropping malformed: ',flights_none_missing.count())\n",
        "\n",
        "\n",
        "# Conversion: 'mile' to 'km' and drop 'mile' column\n",
        "flights_km = flights_none_missing.withColumn('km', round(flights.mile * 1.60934, 0)).drop('mile')\n",
        "\n",
        "# Creating 'label' column indicating whether flight delayed (1) or not (0)\n",
        "flights_km = flights_km.withColumn('label', (flights_km.delay >= 15).cast('integer'))\n",
        "\n",
        "# Check records\n",
        "#flights_km.show(5)\n",
        "#flights_km.printSchema()\n",
        "\n",
        "idx_input_cols=['carrier', 'org']\n",
        "idx_output_cols=['carrier_idx', 'org_idx']\n",
        "\n",
        "# Create an indexer\n",
        "indexer = StringIndexer(inputCols=idx_input_cols, outputCols=idx_output_cols)\n",
        "\n",
        "# Indexer identifies categories in the data\n",
        "indexer_model = indexer.fit(flights_km)\n",
        "\n",
        "# Indexer creates a new column with numeric index values\n",
        "flights_indexed = indexer_model.transform(flights_km)\n",
        "\n",
        "# Check result\n",
        "#flights_indexed.show(5,False)\n",
        "\n",
        "# Create an instance of the one hot encoder\n",
        "onehot = OneHotEncoder(inputCols=['org_idx'], outputCols=['org_dummy'])\n",
        "\n",
        "# Apply the one hot encoder to the flights_indexed data\n",
        "onehot = onehot.fit(flights_indexed)\n",
        "flights_onehot = onehot.transform(flights_indexed)\n",
        "\n",
        "# Check the results\n",
        "#flights_onehot.select('org', 'org_idx', 'org_dummy').distinct().sort('org_idx').show()\n",
        "\n",
        "# Create buckets at 3 hour intervals through the day\n",
        "splits=[0,3,6,9,12,15,18,21,24]\n",
        "buckets = Bucketizer(splits=splits, inputCol='depart', outputCol='depart_bucket')\n",
        "\n",
        "# Bucket the departure times\n",
        "bucketed = buckets.transform(flights_onehot)\n",
        "#bucketed.select('depart','depart_bucket').show(5)\n",
        "\n",
        "# Create a one-hot encoder\n",
        "onehot = OneHotEncoder(inputCols=['depart_bucket'], outputCols=['depart_dummy'])\n",
        "\n",
        "# One-hot encode the bucketed departure times\n",
        "flights_onehot = onehot.fit(bucketed).transform(bucketed)\n",
        "#flights_onehot.select('depart', 'depart_bucket', 'depart_dummy').show(5)\n",
        "\n",
        "# Create an assembler object\n",
        "assembler = VectorAssembler(inputCols=['km','org_dummy','depart_dummy','dow','mon'], outputCol='features')\n",
        "\n",
        "# Consolidate predictor columns\n",
        "flights_assembled = assembler.transform(flights_onehot)\n",
        "\n",
        "# Check the resulting column\n",
        "flights_assembled = flights_assembled.select('mon','dom','dow','carrier','org','depart','duration','delay','km',\n",
        "                                             'org_idx','org_dummy','depart_bucket','depart_dummy','features')\n",
        "\n",
        "# Split into training and testing sets in a 80:20 ratio\n",
        "flights_train, flights_test = flights_assembled.randomSplit([0.8, 0.2], seed=7)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NMLDK1DX-b2",
        "outputId": "816a9695-1161-4f8e-f2fb-c402c00af5e4"
      },
      "source": [
        "### MODEL EVALUATION ###\n",
        "\n",
        "# Fit linear regression model to training data\n",
        "regression = LinearRegression(labelCol='duration').fit(flights_train)\n",
        "\n",
        "# Make predictions on testing data\n",
        "predictions = regression.transform(flights_test)\n",
        "\n",
        "# Calculate the RMSE on testing data\n",
        "rmse = RegressionEvaluator(labelCol='duration').evaluate(predictions)\n",
        "print(\"The test RMSE is\", rmse)\n",
        "\n",
        "# Look at the model coefficients\n",
        "coeffs = regression.coefficients\n",
        "print('Regression coefficients are:\\n ',coeffs)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The test RMSE is 10.5733817087635\n",
            "Regression coefficients are:\n",
            "  [0.07440217199394049,27.696657449729237,20.590145822897725,51.83452291203616,45.99926965887334,15.437053513762223,17.931565316893604,17.79852553066936,-14.805760419640027,1.5200493085884204,3.9554969638546966,6.913548613724635,4.669555628501808,8.729855197467081,8.566405052255341,-0.03641255730024152,0.08740640199575375]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHCZpV5daNRH"
      },
      "source": [
        "#Flight duration model: Regularisation!\n",
        "\n",
        "The model performed well on testing data, but with so many coefficients it was difficult to interpret.\n",
        "\n",
        "Using Lasso regression (regularized with a L1 penalty) to create a more parsimonious model.  \n",
        "Many of the coefficients in the resulting model will be set to zero. This means that only a subset of the predictors actually contribute to the model. The objective is to produce the simplier possible model that explain well the data.  \n",
        "\n",
        "A specific value for the regularization strength will be used ($\\alpha =1$). Later a better value will be calculated using cross validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T68vnujHa_73"
      },
      "source": [
        "# Fit Lasso model (α = 1) to training data\n",
        "regression = LinearRegression(labelCol='duration', regParam=1, elasticNetParam=1).fit(flights_train)\n",
        "\n",
        "# Calculate the RMSE on testing data\n",
        "rmse = RegressionEvaluator(labelCol='duration').evaluate(regression.transform(flights_test))\n",
        "print(\"The test RMSE is\", rmse)\n",
        "\n",
        "# Look at the model coefficients\n",
        "coeffs = regression.coefficients\n",
        "print(coeffs)\n",
        "\n",
        "# Number of zero coefficients\n",
        "zero_coeff = sum([beta == 0 for beta in regression.coefficients])\n",
        "print(\"Number of coefficients equal to 0:\", zero_coeff)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}