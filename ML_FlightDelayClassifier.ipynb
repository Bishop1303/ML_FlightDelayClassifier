{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_FlightDelayClassifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPWtoUhZtP6nZeiC0nT1tuB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bishop1303/ML_FlightDelayClassifier/blob/master/ML_FlightDelayClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVXCrX6gNI6G"
      },
      "source": [
        "# Getting the softwares:\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.1.1/spark-3.1.1-bin-hadoop2.7.tgz\n",
        "!tar -xvf spark-3.1.1-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "\n",
        "\n",
        "# To use spark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop2.7\"\n",
        "\n",
        "# SparkSession\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI6S16qUNyee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "269c5f44-5253-4e1e-f10b-1d5ae852b2c8"
      },
      "source": [
        "#Carica il drive con i dati:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WHvbFZbPMQr"
      },
      "source": [
        "flights = spark.read.csv(\"/content/drive/My Drive/flights.csv\", inferSchema=True, header=True, mode='FAILFAST')\n",
        "flights.show()\n",
        "flights.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0n6rnd6QXdA"
      },
      "source": [
        "Tune the raw dataset:\n",
        "\n",
        "1.   Removing an uninformative column, (**flight**).\n",
        "\n",
        "2.   removing rows which do not have information about whether or not a flight was delayed, (condition on **delay** column).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oy8xGsI1QAIR"
      },
      "source": [
        "# Remove the 'flight' column\n",
        "flights_drop_column = flights.drop('flight')\n",
        "\n",
        "# Remove records with missing 'delay' values or NA values\n",
        "flights_none_missing = flights_drop_column.filter((flights_drop_column.delay.isNotNull()) & \\\n",
        "                                                  (flights_drop_column.delay != 'NA'))\n",
        "\n",
        "#Change delay column type form str to int\n",
        "flights_none_missing = flights_none_missing.withColumn('delay', flights_none_missing['delay'].cast('int'))\n",
        "\n",
        "# Check on dataframe\n",
        "print('The Schema is: ')\n",
        "flights_none_missing.printSchema()\n",
        "print('=====================================================')\n",
        "print('Informative rows after dropping malformed: ',flights_none_missing.count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmWxGta5ROKO"
      },
      "source": [
        "# Tweaking the data:\n",
        "\n",
        "\n",
        "1.   Converting the units of distance, replacing the *mile* column with a *km* column\n",
        "2.   Creating a Boolean column indicating whether or not a flight was delayed, (>15 mins = delayed)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEUj0ToNRHJw"
      },
      "source": [
        "# Import the required function\n",
        "from pyspark.sql.functions import round\n",
        "\n",
        "# Conversion: 'mile' to 'km' and drop 'mile' column\n",
        "flights_km = flights_none_missing.withColumn('km', round(flights.mile * 1.60934, 0)).drop('mile')\n",
        "\n",
        "# Creating 'label' column indicating whether flight delayed (1) or not (0)\n",
        "flights_km = flights_km.withColumn('label', (flights_km.delay >= 15).cast('integer'))\n",
        "\n",
        "# Check records\n",
        "flights_km.show(5)\n",
        "flights_km.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvpa0VQ2SMAT"
      },
      "source": [
        "# Indexing: from string to unique inxed\n",
        "\n",
        "Transforming categorical columns (**carrier**, **org**) in numerical values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FA3MU3NASMfW"
      },
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "# Create an indexer\n",
        "indexer = StringIndexer(inputCol='carrier', outputCol='carrier_idx')\n",
        "\n",
        "# Indexer identifies categories in the data\n",
        "indexer_model = indexer.fit(flights_km)\n",
        "\n",
        "# Indexer creates a new column with numeric index values\n",
        "flights_indexed = indexer_model.transform(flights_km)\n",
        "\n",
        "# Repeat the process for the other categorical feature\n",
        "flights_indexed = StringIndexer(inputCol='org', outputCol='org_idx').fit(flights_indexed).transform(flights_indexed)\n",
        "\n",
        "# Check result\n",
        "flights_indexed.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAlY-Bj1TEjG"
      },
      "source": [
        "# Vector Assembler\n",
        "\n",
        "Consolidate predictor columns into a single column called **features** needed for the *Decision Tree*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpkM-PFFTV6i"
      },
      "source": [
        "# Import the necessary class\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# Create an assembler object\n",
        "assembler = VectorAssembler(inputCols=['mon','dom', 'dow', 'carrier_idx',\n",
        "                                       'org_idx', 'km', 'depart', 'duration'],\n",
        "                             outputCol='features')\n",
        "\n",
        "# Consolidate predictor columns\n",
        "flights_assembled = assembler.transform(flights_indexed)\n",
        "\n",
        "# Check the resulting column\n",
        "flights_assembled.select('features', 'delay').show(5, truncate=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MppB3LcQVGis"
      },
      "source": [
        "# **Decision Tree**\n",
        "\n",
        "**Root node**: contains all the data\n",
        "\n",
        "**Child node**: separate in 2 the main node based on classification criteria.\n",
        "\n",
        "Recursive approch to every child node to keep splitting...\n",
        "\n",
        "In this case the decision tree must use **features** to predict the **delay**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBgjUWkDYk7A"
      },
      "source": [
        "# **Split train/test**\n",
        "\n",
        "Random split the main dataset in 2 sets: training and test. Usually the training set is 80% of the total data, 4 times more then the test set.\n",
        "\n",
        "Splitting data is important: DO NOT TEST MODELS ON TRAINED DATA of course they will perfom well...\n",
        "\n",
        "1.   Training data (used to train the model) about 80% of the total data\n",
        "2.   Testing data (used to test the model) remaning 20% of the data.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQLRb8PvVFwa"
      },
      "source": [
        "# Split into training and testing sets in a 80:20 ratio\n",
        "flights_train, flights_test = flights_assembled.randomSplit([0.8, 0.2], seed=7)\n",
        "\n",
        "# Check that training set has around 80% of records\n",
        "training_ratio = flights_train.count() / flights_test.count()\n",
        "print('Training/Test data ratio is: ',training_ratio)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCRFVOWIYe0_"
      },
      "source": [
        "# Build a Decision Tree\n",
        "Using the data: *flights_train* and *flights_test* to fit a **Decision Tree model**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jF_N6ibWYfY9"
      },
      "source": [
        "# Import the Decision Tree Classifier class\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "\n",
        "# Classifier object\n",
        "tree = DecisionTreeClassifier()\n",
        "\n",
        "# Fiting the training data\n",
        "tree_model = tree.fit(flights_train)\n",
        "\n",
        "# Create predictions for the testing data\n",
        "prediction = tree_model.transform(flights_test)\n",
        "\n",
        "# Check the predictions\n",
        "prediction.select('label', 'prediction', 'probability').show(5, False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePMlYwdjprWu"
      },
      "source": [
        "# **Confusion Matrix**\n",
        "\n",
        "A confusion matrix gives a useful breakdown of predictions versus known values. It has four cells which represent the counts of:\n",
        "\n",
        "* **True Negatives** (**TN**) — model predicts negative outcome & known outcome is negative  \n",
        "\n",
        "*   **True Positives** (**TP**) — model predicts positive outcome & known outcome is positive\n",
        "\n",
        "* **False Negatives** (**FN**) — model predicts negative outcome but known outcome is positive\n",
        "\n",
        "* **False Positives** (**FP**) — model predicts positive outcome but known outcome is negative.\n",
        "\n",
        "$$\\text{accuracy} :=\\frac{(TN+TP)}{(TN+TP+FN+FP)}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuhbVzwoprwy"
      },
      "source": [
        "# Confusion matrix\n",
        "prediction.groupBy('label', 'prediction').count().show()\n",
        "\n",
        "# Calculate the elements of the confusion matrix\n",
        "TN = prediction.filter('prediction = 0 AND label = prediction').count()\n",
        "TP = prediction.filter('prediction = 1 AND label = prediction').count()\n",
        "FN = prediction.filter('prediction = 0 AND label = 1').count()\n",
        "FP = prediction.filter('prediction = 1 AND label = 0').count()\n",
        "\n",
        "# Accuracy measures the proportion of correct predictions\n",
        "accuracy = (TN + TP) / (TN + TP + FN + FP)\n",
        "\n",
        "# Check accuracy\n",
        "print('The model accuracy is: ', '{:.3f}'.format(accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AGR3T0puFLe"
      },
      "source": [
        "# Logistic Curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7V0mTJBvgfX"
      },
      "source": [
        "# Import the logistic regression class\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "# Create a classifier object and train on training data\n",
        "logistic = LogisticRegression().fit(flights_train)\n",
        "\n",
        "# Create predictions for the testing data and show confusion matrix\n",
        "prediction = logistic.transform(flights_test)\n",
        "\n",
        "# Confusion matrix\n",
        "prediction.groupBy('label', 'prediction').count().show()\n",
        "\n",
        "# Calculate the elements of the confusion matrix\n",
        "TN = prediction.filter('prediction = 0 AND label = prediction').count()\n",
        "TP = prediction.filter('prediction = 1 AND label = prediction').count()\n",
        "FN = prediction.filter('prediction = 0 AND label = 1').count()\n",
        "FP = prediction.filter('prediction = 1 AND label = 0').count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQ6AxeRQv4B3"
      },
      "source": [
        "# **Evaluate the Logistic Regression model**\n",
        "\n",
        "Accuracy is generally not a very reliable metric because it can be biased by the most common target class.\n",
        "\n",
        "\n",
        "\n",
        "*   **precision**: is the proportion of positive predictions which are correct. For all flights which are predicted to be delayed, (i.e. what proportion is actually delayed?)\n",
        "$$\\text{precision} := \\frac{TP}{(TP+FP)}$$\n",
        "\n",
        "\n",
        "*   **recall**: is the proportion of positives outcomes which are correctly predicted. For all delayed flights, (i.e. what proportion is correctly predicted by the model?)\n",
        "$$\\text{recall} := \\frac{TP}{(TP+FN)}$$\n",
        "\n",
        "\n",
        "*The precision and recall are generally formulated in terms of the positive target class. But it's also possible to calculate weighted versions of these metrics which look at both target classes.*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoqU7SbAwntZ"
      },
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
        "\n",
        "# Calculate precision and recall\n",
        "precision = TP / (TP + FP)\n",
        "recall = TP / (TP + FN)\n",
        "\n",
        "print('precision = {:.2f}\\n recall = {:.2f}'.format(precision, recall))\n",
        "\n",
        "# Find weighted precision\n",
        "multi_evaluator = MulticlassClassificationEvaluator()\n",
        "weighted_precision = multi_evaluator.evaluate(prediction, {multi_evaluator.metricName: 'weightedPrecision'})\n",
        "\n",
        "# Find AUC\n",
        "binary_evaluator = BinaryClassificationEvaluator()\n",
        "auc = binary_evaluator.evaluate(prediction, {binary_evaluator.metricName: 'areaUnderROC'})\n",
        "\n",
        "# AOC, should be near 1\n",
        "print('The area under the curve is: ','{:.2f}'.format(auc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnNNns4uyOKy"
      },
      "source": [
        "# Encoding flight origin (One-Hot Encoding)\n",
        "\n",
        "The **org** column in the flights data is a categorical variable giving the airport from which a flight departs.\n",
        "\n",
        "some values are:\n",
        "\n",
        "* ORD — O'Hare International Airport (Chicago).\n",
        "* SFO — San Francisco International Airport.\n",
        "* JFK — John F Kennedy International Airport (New York).\n",
        "* LGA — La Guardia Airport (New York).\n",
        "* SMF — Sacramento.\n",
        "* SJC — San Jose.\n",
        "* TUS — Tucson International Airport.\n",
        "* OGG — Kahului (Hawaii).\n",
        "* ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TImAjJVYzRgq"
      },
      "source": [
        "# Import the one hot encoder class\n",
        "from pyspark.ml.feature import OneHotEncoder\n",
        "\n",
        "# Create an instance of the one hot encoder\n",
        "onehot = OneHotEncoder(inputCols=['org_idx'], outputCols=['org_dummy'])\n",
        "\n",
        "# Apply the one hot encoder to the flights_km data\n",
        "onehot = onehot.fit(flights_indexed)\n",
        "flights_onehot = onehot.transform(flights_indexed)\n",
        "\n",
        "# Check the results\n",
        "flights_onehot.select('org', 'org_idx', 'org_dummy').distinct().sort('org_idx').show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRSJEcLy2m0M"
      },
      "source": [
        "# Flight duration model: Just distance\n",
        "\n",
        "The objective is to predict flight duration (the duration column) by using only the distance of the flight (the km column) as a predictor.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tR4q_zAE7Nqn"
      },
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# Create an assembler object\n",
        "assembler = VectorAssembler(inputCols=['km'], outputCol='features')\n",
        "\n",
        "# Consolidate predictor columns\n",
        "flights_assembled = assembler.transform(flights_onehot)\n",
        "\n",
        "# Check the resulting column\n",
        "flights_assembled = flights_assembled.select('mon','dom','dow','carrier','org','depart','duration','delay','km',\n",
        "                                             'org_idx','org_dummy','features')\n",
        "\n",
        "# Split into training and testing sets in a 80:20 ratio\n",
        "flights_train, flights_test = flights_assembled.randomSplit([0.8, 0.2], seed=7)\n",
        "\n",
        "# Create a regression object and train on training data\n",
        "regression = LinearRegression(labelCol='duration').fit(flights_train)\n",
        "\n",
        "# Create predictions for the testing data and take a look at the predictions\n",
        "predictions = regression.transform(flights_test)\n",
        "predictions.select('duration', 'prediction').show(5, False)\n",
        "\n",
        "# Calculate the RMSE\n",
        "print('The RMSE of the model is:')\n",
        "RegressionEvaluator(labelCol='duration').evaluate(predictions)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4ycEy_v-8gN"
      },
      "source": [
        "# Interpreting the coefficients\n",
        "The linear regression model for flight duration as a function of distance takes the form:\n",
        "\n",
        "$$\\text{duration} = \\alpha + \\beta \\times \\text{distance}$$\n",
        "\n",
        "Where:\n",
        "\n",
        " * $\\alpha$ is the *intercept*, i.e. component of duration which does not depend on distance.\n",
        "\n",
        " * $\\beta$ is the coefficient (or the *slope*), i.e. the rate at which duration increases as a function of distance.\n",
        "\n",
        "By looking at the coefficients of your model you will be able to infer:\n",
        "\n",
        "* How much of the average flight duration is actually spent on the ground.\n",
        "\n",
        "* What the average speed is during a flight."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Balwpbo_47h"
      },
      "source": [
        "# Intercept (average minutes on ground)\n",
        "inter = regression.intercept\n",
        "print('The intercep of your model is: ',inter)\n",
        "\n",
        "# Coefficients\n",
        "#coefs = regression.coefficients\n",
        "#print('The regression coefficient  ',coefs)\n",
        "\n",
        "# Average minutes per km\n",
        "minutes_per_km = regression.coefficients[0]\n",
        "print('The regression coefficient rapresent the minutes per km: ', '{:,.3f}'.format(minutes_per_km))\n",
        "\n",
        "# Average speed in km per hour\n",
        "avg_speed = 60 / minutes_per_km\n",
        "print('The average speed is: ', '{:,.2f}'.format(avg_speed), 'km/h')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HygeceHmFKL5"
      },
      "source": [
        "#Flight duration model: Adding origin airport\n",
        "\n",
        "It stands to reason that the duration of a flight might depend not only on the distance being covered but also the airport from which the flight departs.\n",
        "\n",
        "Include the departure airport as a predictor to see if the statement is true."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKzYOvpXGNW1"
      },
      "source": [
        "# Create an assembler object\n",
        "assembler = VectorAssembler(inputCols=['km','org_dummy'], outputCol='features2')\n",
        "# The vector has km at position 0, so all the org_index are shifted:\n",
        "# i.e. ORD was in position 0 now is at index 1 in the feature2 vector.\n",
        "\n",
        "\n",
        "# Consolidate predictor columns\n",
        "flights_assembled2 = assembler.transform(flights_onehot)\n",
        "\n",
        "# Check the resulting column\n",
        "flights_assembled2 = flights_assembled2.select('mon','dom','dow','carrier','org','depart','duration','delay','km',\n",
        "                                             'org_idx','org_dummy','features2')\n",
        "\n",
        "# Split into training and testing sets in a 80:20 ratio\n",
        "flights_train2, flights_test2 = flights_assembled2.randomSplit([0.8, 0.2], seed=7)\n",
        "\n",
        "# Create a regression object and train on training data\n",
        "regression = LinearRegression(featuresCol='features2',labelCol='duration').fit(flights_train2)\n",
        "\n",
        "\n",
        "# Create predictions for the testing data\n",
        "predictions = regression.transform(flights_test2)\n",
        "predictions.select('duration', 'prediction').show(5, False)\n",
        "\n",
        "# Calculate the RMSE\n",
        "print('The RMSE of the model is:')\n",
        "RegressionEvaluator(labelCol='duration').evaluate(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-lZ5OmxKbza"
      },
      "source": [
        "# Interpreting coefficients\n",
        "\n",
        "Origin airport, **org**, has eight possible values (ORD, SFO, JFK, LGA, SMF, SJC, TUS and OGG) which have been one-hot encoded to seven dummy variables in **org_dummy**.  \n",
        "\n",
        "The values for **km** and **org_dummy** have been assembled into **features**, which has eight columns with *sparse representation*. Column indices in features are as follows:\n",
        "\n",
        "* 0 — km,\n",
        "* 1 — ORD,\n",
        "* 2 — SFO,\n",
        "* 3 — JFK,\n",
        "* 4 — LGA,\n",
        "* 5 — SMF,\n",
        "* 6 — SJC,\n",
        "* 7 — TUS.\n",
        "\n",
        "Note that **OGG** does not appear in this list because it is the *reference level* for the origin airport category. So every average time on ground is equal to = (intercept + coefficent relative to that airport) as the list above shows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5N-_sVjKcKc"
      },
      "source": [
        "# Coefficients\n",
        "coefs = regression.coefficients\n",
        "print('The regression coefficients are:\\n',coefs)\n",
        "\n",
        "# Average speed in km per hour\n",
        "avg_speed_hour = 60 / regression.coefficients[0]\n",
        "print('The average speed is: ','{:,.2f}'.format(avg_speed_hour), 'km/h')\n",
        "\n",
        "# Average minutes on ground at OGG\n",
        "inter = regression.intercept\n",
        "print('The average time on ground at OGG is: ','{:,.1f}'.format(inter), 'minutes')\n",
        "\n",
        "# Average minutes on ground at JFK\n",
        "avg_ground_jfk = inter + regression.coefficients[3]\n",
        "print('The average time on ground at JFK is: ','{:,.1f}'.format(avg_ground_jfk), 'minutes')\n",
        "\n",
        "# Average minutes on ground at LGA\n",
        "avg_ground_lga = inter + regression.coefficients[4]\n",
        "print('The average time on ground at LGA is: ','{:,.1f}'.format(avg_ground_lga), 'minutes')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}