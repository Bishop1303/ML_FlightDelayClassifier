{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_FlightDelayClassifier.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP8FUIdelHO9iT75oK8jtKU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bishop1303/ML_FlightDelayClassifier/blob/master/ML_FlightDelayClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVXCrX6gNI6G"
      },
      "source": [
        "# Getting the softwares:\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.1.1/spark-3.1.1-bin-hadoop2.7.tgz\n",
        "!tar -xvf spark-3.1.1-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "\n",
        "\n",
        "# To use spark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop2.7\"\n",
        "\n",
        "# SparkSession\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI6S16qUNyee"
      },
      "source": [
        "#Carica il drive con i dati:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WHvbFZbPMQr",
        "outputId": "f8818bc7-02ab-489d-ebb5-969684c294b1"
      },
      "source": [
        "flights = spark.read.csv(\"/content/drive/My Drive/flights.csv\", inferSchema=True, header=True, mode='FAILFAST')\n",
        "flights.show()\n",
        "flights.printSchema()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---+---+-------+------+---+----+------+--------+-----+\n",
            "|mon|dom|dow|carrier|flight|org|mile|depart|duration|delay|\n",
            "+---+---+---+-------+------+---+----+------+--------+-----+\n",
            "| 11| 20|  6|     US|    19|JFK|2153|  9.48|     351|   NA|\n",
            "|  0| 22|  2|     UA|  1107|ORD| 316| 16.33|      82|   30|\n",
            "|  2| 20|  4|     UA|   226|SFO| 337|  6.17|      82|   -8|\n",
            "|  9| 13|  1|     AA|   419|ORD|1236| 10.33|     195|   -5|\n",
            "|  4|  2|  5|     AA|   325|ORD| 258|  8.92|      65|   NA|\n",
            "|  5|  2|  1|     UA|   704|SFO| 550|  7.98|     102|    2|\n",
            "|  7|  2|  6|     AA|   380|ORD| 733| 10.83|     135|   54|\n",
            "|  1| 16|  6|     UA|  1477|ORD|1440|   8.0|     232|   -7|\n",
            "|  1| 22|  5|     UA|   620|SJC|1829|  7.98|     250|  -13|\n",
            "| 11|  8|  1|     OO|  5590|SFO| 158|  7.77|      60|   88|\n",
            "|  4| 26|  1|     AA|  1144|SFO|1464| 13.25|     210|  -10|\n",
            "|  4| 25|  0|     AA|   321|ORD| 978| 13.75|     160|   31|\n",
            "|  8| 30|  2|     UA|   646|ORD| 719| 13.28|     151|   16|\n",
            "|  3| 16|  3|     UA|   107|ORD|1745|   9.0|     264|    3|\n",
            "|  0|  3|  4|     AA|  1559|LGA|1097| 17.08|     190|   32|\n",
            "|  5|  9|  1|     UA|   770|SFO| 967|  12.7|     158|   20|\n",
            "|  3| 10|  4|     B6|   937|ORD|1735| 17.58|     265|  155|\n",
            "| 11| 15|  1|     AA|  2303|ORD| 802|  6.75|     160|   23|\n",
            "|  8| 18|  4|     UA|   802|SJC| 948|  6.33|     160|   17|\n",
            "|  2| 14|  5|     B6|    71|JFK| 944|  6.17|     166|    0|\n",
            "+---+---+---+-------+------+---+----+------+--------+-----+\n",
            "only showing top 20 rows\n",
            "\n",
            "root\n",
            " |-- mon: integer (nullable = true)\n",
            " |-- dom: integer (nullable = true)\n",
            " |-- dow: integer (nullable = true)\n",
            " |-- carrier: string (nullable = true)\n",
            " |-- flight: integer (nullable = true)\n",
            " |-- org: string (nullable = true)\n",
            " |-- mile: integer (nullable = true)\n",
            " |-- depart: double (nullable = true)\n",
            " |-- duration: integer (nullable = true)\n",
            " |-- delay: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0n6rnd6QXdA"
      },
      "source": [
        "Tune the raw dataset:\n",
        "\n",
        "1.   Removing an uninformative column, (**flight**).\n",
        "\n",
        "2.   removing rows which do not have information about whether or not a flight was delayed, (condition on **delay** column).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oy8xGsI1QAIR",
        "outputId": "a697c634-0564-4d6f-cab3-78a89ec802de"
      },
      "source": [
        "# Remove the 'flight' column\n",
        "flights_drop_column = flights.drop('flight')\n",
        "\n",
        "# Remove records with missing 'delay' values or NA values\n",
        "flights_none_missing = flights_drop_column.filter((flights_drop_column.delay.isNotNull()) & \\\n",
        "                                                  (flights_drop_column.delay != 'NA'))\n",
        "\n",
        "\n",
        "\n",
        "flights_none_missing = flights_none_missing.withColumn('delay', flights_none_missing['delay'].cast('int'))\n",
        "\n",
        "# Check on dataframe\n",
        "print('The Schema is: ')\n",
        "flights_none_missing.printSchema()\n",
        "print('=====================================================')\n",
        "print('Informative rows after dropping malformed: ',flights_none_missing.count())"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Schema is: \n",
            "root\n",
            " |-- mon: integer (nullable = true)\n",
            " |-- dom: integer (nullable = true)\n",
            " |-- dow: integer (nullable = true)\n",
            " |-- carrier: string (nullable = true)\n",
            " |-- org: string (nullable = true)\n",
            " |-- mile: integer (nullable = true)\n",
            " |-- depart: double (nullable = true)\n",
            " |-- duration: integer (nullable = true)\n",
            " |-- delay: integer (nullable = true)\n",
            "\n",
            "=====================================================\n",
            "Informative rows after dropping malformed:  47022\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmWxGta5ROKO"
      },
      "source": [
        "Tweaking the data:\n",
        "\n",
        "\n",
        "1.   Converting the units of distance, replacing the *mile* column with a *km* column\n",
        "2.   Creating a Boolean column indicating whether or not a flight was delayed, (>15 mins = delayed)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEUj0ToNRHJw",
        "outputId": "dfc8fc6c-488d-4f19-ba38-a0e33f2dd09b"
      },
      "source": [
        "# Import the required function\n",
        "from pyspark.sql.functions import round\n",
        "\n",
        "# Conversion: 'mile' to 'km' and drop 'mile' column\n",
        "flights_km = flights_none_missing.withColumn('km', round(flights.mile * 1.60934, 0)).drop('mile')\n",
        "\n",
        "# Creating 'label' column indicating whether flight delayed (1) or not (0)\n",
        "flights_km = flights_km.withColumn('label', (flights_km.delay >= 15).cast('integer'))\n",
        "\n",
        "# Check records\n",
        "flights_km.show(5)\n",
        "flights_km.printSchema()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
            "|mon|dom|dow|carrier|org|depart|duration|delay|    km|label|\n",
            "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
            "|  0| 22|  2|     UA|ORD| 16.33|      82|   30| 509.0|    1|\n",
            "|  2| 20|  4|     UA|SFO|  6.17|      82|   -8| 542.0|    0|\n",
            "|  9| 13|  1|     AA|ORD| 10.33|     195|   -5|1989.0|    0|\n",
            "|  5|  2|  1|     UA|SFO|  7.98|     102|    2| 885.0|    0|\n",
            "|  7|  2|  6|     AA|ORD| 10.83|     135|   54|1180.0|    1|\n",
            "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- mon: integer (nullable = true)\n",
            " |-- dom: integer (nullable = true)\n",
            " |-- dow: integer (nullable = true)\n",
            " |-- carrier: string (nullable = true)\n",
            " |-- org: string (nullable = true)\n",
            " |-- depart: double (nullable = true)\n",
            " |-- duration: integer (nullable = true)\n",
            " |-- delay: integer (nullable = true)\n",
            " |-- km: double (nullable = true)\n",
            " |-- label: integer (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvpa0VQ2SMAT"
      },
      "source": [
        "Transforming categorical columns (**carrier**, **org**) in numerical values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FA3MU3NASMfW",
        "outputId": "8945879b-dce4-40be-c53a-fa7e5e180ac1"
      },
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "# Create an indexer\n",
        "indexer = StringIndexer(inputCol='carrier', outputCol='carrier_idx')\n",
        "\n",
        "# Indexer identifies categories in the data\n",
        "indexer_model = indexer.fit(flights_km)\n",
        "\n",
        "# Indexer creates a new column with numeric index values\n",
        "flights_indexed = indexer_model.transform(flights_km)\n",
        "\n",
        "# Repeat the process for the other categorical feature\n",
        "flights_indexed = StringIndexer(inputCol='org', outputCol='org_idx').fit(flights_indexed).transform(flights_indexed)\n",
        "\n",
        "# Check result\n",
        "flights_indexed.show()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+\n",
            "|mon|dom|dow|carrier|org|depart|duration|delay|    km|label|carrier_idx|org_idx|\n",
            "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+\n",
            "|  0| 22|  2|     UA|ORD| 16.33|      82|   30| 509.0|    1|        0.0|    0.0|\n",
            "|  2| 20|  4|     UA|SFO|  6.17|      82|   -8| 542.0|    0|        0.0|    1.0|\n",
            "|  9| 13|  1|     AA|ORD| 10.33|     195|   -5|1989.0|    0|        1.0|    0.0|\n",
            "|  5|  2|  1|     UA|SFO|  7.98|     102|    2| 885.0|    0|        0.0|    1.0|\n",
            "|  7|  2|  6|     AA|ORD| 10.83|     135|   54|1180.0|    1|        1.0|    0.0|\n",
            "|  1| 16|  6|     UA|ORD|   8.0|     232|   -7|2317.0|    0|        0.0|    0.0|\n",
            "|  1| 22|  5|     UA|SJC|  7.98|     250|  -13|2943.0|    0|        0.0|    5.0|\n",
            "| 11|  8|  1|     OO|SFO|  7.77|      60|   88| 254.0|    1|        2.0|    1.0|\n",
            "|  4| 26|  1|     AA|SFO| 13.25|     210|  -10|2356.0|    0|        1.0|    1.0|\n",
            "|  4| 25|  0|     AA|ORD| 13.75|     160|   31|1574.0|    1|        1.0|    0.0|\n",
            "|  8| 30|  2|     UA|ORD| 13.28|     151|   16|1157.0|    1|        0.0|    0.0|\n",
            "|  3| 16|  3|     UA|ORD|   9.0|     264|    3|2808.0|    0|        0.0|    0.0|\n",
            "|  0|  3|  4|     AA|LGA| 17.08|     190|   32|1765.0|    1|        1.0|    3.0|\n",
            "|  5|  9|  1|     UA|SFO|  12.7|     158|   20|1556.0|    1|        0.0|    1.0|\n",
            "|  3| 10|  4|     B6|ORD| 17.58|     265|  155|2792.0|    1|        4.0|    0.0|\n",
            "| 11| 15|  1|     AA|ORD|  6.75|     160|   23|1291.0|    1|        1.0|    0.0|\n",
            "|  8| 18|  4|     UA|SJC|  6.33|     160|   17|1526.0|    1|        0.0|    5.0|\n",
            "|  2| 14|  5|     B6|JFK|  6.17|     166|    0|1519.0|    0|        4.0|    2.0|\n",
            "|  7| 21|  4|     OO|ORD|  19.0|     110|   21| 977.0|    1|        2.0|    0.0|\n",
            "| 11|  6|  6|     OO|SFO|  8.75|      82|   40| 509.0|    1|        2.0|    1.0|\n",
            "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAlY-Bj1TEjG"
      },
      "source": [
        "Consolidate predictor columns into a single column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpkM-PFFTV6i",
        "outputId": "477bad4e-3c63-4311-9f6e-e81092c4695d"
      },
      "source": [
        "# Import the necessary class\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# Create an assembler object\n",
        "assembler = VectorAssembler(inputCols=['mon',\n",
        "    'dom', 'dow', 'carrier_idx', 'org_idx', 'km', 'depart', 'duration'\n",
        "], outputCol='features')\n",
        "\n",
        "# Consolidate predictor columns\n",
        "flights_assembled = assembler.transform(flights_indexed)\n",
        "\n",
        "# Check the resulting column\n",
        "flights_assembled.select('features', 'delay').show(5, truncate=False)\n"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------------------------+-----+\n",
            "|features                                 |delay|\n",
            "+-----------------------------------------+-----+\n",
            "|[0.0,22.0,2.0,0.0,0.0,509.0,16.33,82.0]  |30   |\n",
            "|[2.0,20.0,4.0,0.0,1.0,542.0,6.17,82.0]   |-8   |\n",
            "|[9.0,13.0,1.0,1.0,0.0,1989.0,10.33,195.0]|-5   |\n",
            "|[5.0,2.0,1.0,0.0,1.0,885.0,7.98,102.0]   |2    |\n",
            "|[7.0,2.0,6.0,1.0,0.0,1180.0,10.83,135.0] |54   |\n",
            "+-----------------------------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MppB3LcQVGis"
      },
      "source": [
        "# **Decision Tree**\n",
        "root node: contains all the data\n",
        "\n",
        "Child node: separate in 2 the main node based on classification criteria.\n",
        "\n",
        "Recursive approch to every child node to keep splitting...\n",
        "\n",
        "The decision tree must use **features** to predict **delay**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBgjUWkDYk7A"
      },
      "source": [
        "# **Split train/test**\n",
        "\n",
        "Random split the main dataset in 2 sets: training and test. Usually the training set is 80% of the total data, 4 times more then the test set.\n",
        "\n",
        "Splitting data is important: DO NOT TEST MODELS ON TRAINED DATA of course they will perfom well...\n",
        "\n",
        "1.   Training data (used to train the model) about 80% of the total data\n",
        "2.   Testing data (used to test the model) remaning 20% of the data.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQLRb8PvVFwa",
        "outputId": "6a13a80b-a335-4289-c557-7249085e18ad"
      },
      "source": [
        "# Split into training and testing sets in a 80:20 ratio\n",
        "flights_train, flights_test = flights_assembled.randomSplit([0.8, 0.2], seed=7)\n",
        "\n",
        "# Check that training set has around 80% of records\n",
        "training_ratio = flights_train.count() / flights_test.count()\n",
        "print('Training/Test data ratio is: ',training_ratio)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training/Test data ratio is:  3.944479495268139\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCRFVOWIYe0_"
      },
      "source": [
        "# Build a Decision Tree\n",
        "Using the data: *flights_train* and *flights_test* to fit a **Decision Tree model**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jF_N6ibWYfY9",
        "outputId": "63790c48-7beb-4bf2-d121-82e460dc3989"
      },
      "source": [
        "# Import the Decision Tree Classifier class\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "\n",
        "# Classifier object\n",
        "tree = DecisionTreeClassifier()\n",
        "\n",
        "# Fiting the training data\n",
        "tree_model = tree.fit(flights_train)\n",
        "\n",
        "# Create predictions for the testing data\n",
        "prediction = tree_model.transform(flights_test)\n",
        "\n",
        "# Check the predictions\n",
        "prediction.select('label', 'prediction', 'probability').show(5, False)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+----------+---------------------------------------+\n",
            "|label|prediction|probability                            |\n",
            "+-----+----------+---------------------------------------+\n",
            "|1    |0.0       |[0.5393553223388305,0.4606446776611694]|\n",
            "|0    |1.0       |[0.3447961260439329,0.655203873956067] |\n",
            "|1    |1.0       |[0.3411764705882353,0.6588235294117647]|\n",
            "|1    |0.0       |[0.5393553223388305,0.4606446776611694]|\n",
            "|1    |1.0       |[0.3447961260439329,0.655203873956067] |\n",
            "+-----+----------+---------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePMlYwdjprWu"
      },
      "source": [
        "# **Confusion Matrix**\n",
        "\n",
        "A confusion matrix gives a useful breakdown of predictions versus known values. It has four cells which represent the counts of:\n",
        "\n",
        "* **True Negatives** (**TN**) — model predicts negative outcome & known outcome is negative  \n",
        "\n",
        "*   **True Positives** (**TP**) — model predicts positive outcome & known outcome is positive\n",
        "\n",
        "* **False Negatives** (**FN**) — model predicts negative outcome but known outcome is positive\n",
        "\n",
        "* **False Positives** (**FP**) — model predicts positive outcome but known outcome is negative.\n",
        "\n",
        "$$\\text{accuracy} :=\\frac{(TN+TP)}{(TN+TP+FN+FP)}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuhbVzwoprwy",
        "outputId": "2f461a6c-e3c4-4bf2-c348-905ff0c62eab"
      },
      "source": [
        "# Confusion matrix\n",
        "prediction.groupBy('label', 'prediction').count().show()\n",
        "\n",
        "# Calculate the elements of the confusion matrix\n",
        "TN = prediction.filter('prediction = 0 AND label = prediction').count()\n",
        "TP = prediction.filter('prediction = 1 AND label = prediction').count()\n",
        "FN = prediction.filter('prediction = 0 AND label = 1').count()\n",
        "FP = prediction.filter('prediction = 1 AND label = 0').count()\n",
        "\n",
        "# Accuracy measures the proportion of correct predictions\n",
        "accuracy = (TN + TP) / (TN + TP + FN + FP)\n",
        "\n",
        "# Check accuracy\n",
        "print('The model accuracy is: ', '{:.3f}'.format(accuracy))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+----------+-----+\n",
            "|label|prediction|count|\n",
            "+-----+----------+-----+\n",
            "|    1|       0.0| 1365|\n",
            "|    0|       0.0| 2586|\n",
            "|    1|       1.0| 3512|\n",
            "|    0|       1.0| 2047|\n",
            "+-----+----------+-----+\n",
            "\n",
            "The model accuracy is:  0.641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AGR3T0puFLe"
      },
      "source": [
        "# Logistic Curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7V0mTJBvgfX",
        "outputId": "30aa4843-cda5-4b28-f3e0-a98b2341df06"
      },
      "source": [
        "# Import the logistic regression class\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "# Create a classifier object and train on training data\n",
        "logistic = LogisticRegression().fit(flights_train)\n",
        "\n",
        "# Create predictions for the testing data and show confusion matrix\n",
        "prediction = logistic.transform(flights_test)\n",
        "\n",
        "# Confusion matrix\n",
        "prediction.groupBy('label', 'prediction').count().show()\n",
        "\n",
        "# Calculate the elements of the confusion matrix\n",
        "TN = prediction.filter('prediction = 0 AND label = prediction').count()\n",
        "TP = prediction.filter('prediction = 1 AND label = prediction').count()\n",
        "FN = prediction.filter('prediction = 0 AND label = 1').count()\n",
        "FP = prediction.filter('prediction = 1 AND label = 0').count()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+----------+-----+\n",
            "|label|prediction|count|\n",
            "+-----+----------+-----+\n",
            "|    1|       0.0| 1738|\n",
            "|    0|       0.0| 2615|\n",
            "|    1|       1.0| 3139|\n",
            "|    0|       1.0| 2018|\n",
            "+-----+----------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQ6AxeRQv4B3"
      },
      "source": [
        "# **Evaluate the Logistic Regression model**\n",
        "\n",
        "Accuracy is generally not a very reliable metric because it can be biased by the most common target class.\n",
        "\n",
        "\n",
        "\n",
        "*   **precision**: is the proportion of positive predictions which are correct. For all flights which are predicted to be delayed, (i.e. what proportion is actually delayed?)\n",
        "$$\\text{precision} := \\frac{TP}{(TP+FP)}$$\n",
        "\n",
        "\n",
        "*   **recall**: is the proportion of positives outcomes which are correctly predicted. For all delayed flights, (i.e. what proportion is correctly predicted by the model?)\n",
        "$$\\text{recall} := \\frac{TP}{(TP+FN)}$$\n",
        "\n",
        "\n",
        "*The precision and recall are generally formulated in terms of the positive target class. But it's also possible to calculate weighted versions of these metrics which look at both target classes.*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoqU7SbAwntZ",
        "outputId": "1e8e7f56-b7ff-42af-8820-aa3e802a553a"
      },
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
        "\n",
        "# Calculate precision and recall\n",
        "precision = TP / (TP + FP)\n",
        "recall = TP / (TP + FN)\n",
        "\n",
        "print('precision = {:.2f}\\n recall = {:.2f}'.format(precision, recall))\n",
        "\n",
        "# Find weighted precision\n",
        "multi_evaluator = MulticlassClassificationEvaluator()\n",
        "weighted_precision = multi_evaluator.evaluate(prediction, {multi_evaluator.metricName: 'weightedPrecision'})\n",
        "\n",
        "# Find AUC\n",
        "binary_evaluator = BinaryClassificationEvaluator()\n",
        "auc = binary_evaluator.evaluate(prediction, {binary_evaluator.metricName: 'areaUnderROC'})\n",
        "\n",
        "# AOC, should be near 1\n",
        "print('The area under the curve is: ','{:.2f}'.format(auc))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precision = 0.61\n",
            " recall = 0.64\n",
            "The area under the curve is:  0.65\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}